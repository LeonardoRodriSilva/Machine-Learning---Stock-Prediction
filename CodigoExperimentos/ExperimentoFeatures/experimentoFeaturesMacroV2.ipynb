{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c58da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tempfile\n",
    "import uuid\n",
    "\n",
    "def carregar_dados_ticker(ticker, pasta_dados_tratados, tipo_experimento):\n",
    "    if tipo_experimento == \"macro\":\n",
    "        nome_arquivo = f\"{ticker}_MacroData_Tratado.csv\"\n",
    "    elif tipo_experimento == \"unificados\":\n",
    "        nome_arquivo = f\"{ticker}_dados_unificados.csv\"\n",
    "    else:\n",
    "        nome_arquivo = f\"{ticker}_dados_unificados.csv\"\n",
    "    \n",
    "    caminho_arquivo = os.path.join(pasta_dados_tratados, nome_arquivo)\n",
    "\n",
    "    if not os.path.exists(caminho_arquivo):\n",
    "        print(f\"Erro: Arquivo n√£o encontrado para {ticker} em {caminho_arquivo}\")\n",
    "        return None, None, None\n",
    "\n",
    "    try:\n",
    "        print(f\"Carregando dados tratados de: {caminho_arquivo}\")\n",
    "        \n",
    "        if 'Data' in pd.read_csv(caminho_arquivo, nrows=0).columns:\n",
    "            df = pd.read_csv(caminho_arquivo, parse_dates=['Data'], index_col='Data')\n",
    "        else:\n",
    "            df = pd.read_csv(caminho_arquivo, index_col=0)\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            df.index.name = 'Data'\n",
    "\n",
    "        colunas_renomear = {}\n",
    "        for col in df.columns:\n",
    "            if col.startswith(\"('\") and col.endswith(\"')\"):\n",
    "                print(f\"Renomeando coluna original: '{col}' para 'Original_Close'\")\n",
    "                colunas_renomear[col] = 'Original_Close'\n",
    "\n",
    "        if colunas_renomear:\n",
    "            df.rename(columns=colunas_renomear, inplace=True)\n",
    "\n",
    "        if 'Close_Feature' not in df.columns or 'Close_Target' not in df.columns:\n",
    "            if 'Pre√ßo' in df.columns and tipo_experimento == \"micro\":\n",
    "                df['Close_Feature'] = df['Pre√ßo']\n",
    "                df['Close_Target'] = df['Pre√ßo'].shift(-1)\n",
    "            else:\n",
    "                print(f\"Erro: Colunas necess√°rias n√£o encontradas no arquivo {nome_arquivo}\")\n",
    "                return None, None, None\n",
    "\n",
    "        target_col = 'Close_Target'\n",
    "        feature_cols = [col for col in df.columns if col not in [target_col, 'Original_Close']]\n",
    "\n",
    "        print(f\"Colunas de Features identificadas para {ticker}: {feature_cols}\")\n",
    "        print(f\"Coluna Target identificada para {ticker}: {target_col}\")\n",
    "\n",
    "        df.dropna(subset=[target_col], inplace=True)\n",
    "\n",
    "        return df, feature_cols, target_col\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar ou processar o arquivo {caminho_arquivo}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None\n",
    "\n",
    "def criar_janelas_multivariadas(features_array, target_array, janela):\n",
    "    X, y = [], []\n",
    "    if len(features_array) <= janela:\n",
    "        print(f\"Aviso em criar_janelas: comprimento dos dados ({len(features_array)}) n√£o √© maior que a janela ({janela}). Retornando vazio.\")\n",
    "        return np.array(X), np.array(y)\n",
    "    for i in range(len(features_array) - janela):\n",
    "        window_features = features_array[i:(i + janela), :]\n",
    "        X.append(window_features)\n",
    "        y.append(target_array[i + janela])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def build_model(hp, input_shape):\n",
    "    model = keras.Sequential()\n",
    "    for i in range(hp.Int('num_lstm_layers', 1, 2)):\n",
    "        return_sequences = i < hp.Int('num_lstm_layers', 1, 2) - 1\n",
    "        model.add(layers.LSTM(\n",
    "            units=hp.Int(f'units_lstm_{i}', min_value=50, max_value=150, step=50),\n",
    "            return_sequences=return_sequences,\n",
    "            input_shape=input_shape if i == 0 else None\n",
    "        ))\n",
    "        model.add(layers.Dropout(hp.Float(f'dropout_lstm_{i}', 0.1, 0.3, step=0.1)))\n",
    "    for i in range(hp.Int('num_dense_layers', 0, 1)):\n",
    "        if hp.Int('num_dense_layers', 0, 1) > 0:\n",
    "            model.add(layers.Dense(\n",
    "                units=hp.Int(f'units_dense_{i}', min_value=32, max_value=64, step=32),\n",
    "                activation='relu'\n",
    "            ))\n",
    "            model.add(layers.Dropout(hp.Float(f'dropout_dense_{i}', 0.1, 0.3, step=0.1)))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-3, 5e-4])),\n",
    "        loss='mean_squared_error'\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tickers = [\"BEEF3.SA\", \"PETR4.SA\", \"SOJA3.SA\", \"GGBR3.SA\", \"CSNA3.SA\", \n",
    "           \"VALE3.SA\", \"JBSS3.SA\", \"BRFS3.SA\", \"SUZB3.SA\"]\n",
    "\n",
    "base_path = r\"C:\\Users\\leona\\OneDrive\\√Årea de Trabalho\\Machine-Learning---Stock-Prediction\\CodigoExperimentos\\ExperimentoFeatures\"\n",
    "\n",
    "pastas_dados = {\n",
    "    \"macro\": os.path.join(base_path, \"dados_macro_csv_processados_tratados\"),\n",
    "    \"unificados\": os.path.join(base_path, \"dados_unificados\"),\n",
    "    \"micro\": os.path.join(base_path, \"dataframesMicro\")\n",
    "}\n",
    "\n",
    "start_date_val = \"2020-01-01\"\n",
    "end_date_val = \"2022-12-31\"\n",
    "start_date_test = \"2023-01-01\"\n",
    "end_date_test = \"2023-12-31\"\n",
    "\n",
    "janela_min = 1\n",
    "janela_max = 4\n",
    "\n",
    "n_splits_cv = 5\n",
    "max_trials_tuner = 10\n",
    "epochs_tuner = 50\n",
    "epochs_final = 100\n",
    "\n",
    "def rodar_experimento_especifico(ticker, janela, df_full, feature_cols, target_col, resultados_base_dir):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üî¨ EXPERIMENTO: {ticker} | Janela {janela}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    ticker_dir = os.path.join(resultados_base_dir, ticker)\n",
    "    base_filename = f\"{ticker}_Janela_{janela}\"\n",
    "    \n",
    "    metrics_path = os.path.join(ticker_dir, \"Metricas\", f\"{base_filename}_metrics.csv\")\n",
    "    hiperparametros_path = os.path.join(ticker_dir, \"Hiperparametros\", f\"{base_filename}_hiperparametros.csv\")\n",
    "    grafico_path = os.path.join(ticker_dir, \"Graficos\", f\"{base_filename}_grafico_teste_final.png\")\n",
    "    previsoes_path = os.path.join(ticker_dir, \"Previsoes\", f\"{base_filename}_previsoes_teste_final.csv\")\n",
    "\n",
    "    if os.path.exists(metrics_path):\n",
    "        print(f\"‚úì Resultados j√° existem para {ticker}, Janela {janela}. Pulando...\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        df_val_train = df_full.loc[start_date_val:end_date_val].copy()\n",
    "        df_test_final = df_full.loc[start_date_test:end_date_test].copy()\n",
    "    except KeyError as e:\n",
    "        print(f\"‚ùå Erro ao dividir dados por data para {ticker}: {e}\")\n",
    "        return\n",
    "\n",
    "    if df_val_train.empty or df_test_final.empty:\n",
    "        print(f\"‚ùå Per√≠odo de treino/valida√ß√£o ou teste est√° vazio para {ticker}.\")\n",
    "        return\n",
    "\n",
    "    if df_val_train[feature_cols].isnull().values.any() or df_val_train[target_col].isnull().values.any():\n",
    "        print(f\"‚ö†Ô∏è NaNs encontrados em treino/valida√ß√£o para {ticker}. Verifique pr√©-processamento.\")\n",
    "        return\n",
    "\n",
    "    if df_test_final[feature_cols].isnull().values.any() or df_test_final[target_col].isnull().values.any():\n",
    "        print(f\"‚ö†Ô∏è NaNs encontrados em teste para {ticker}. Verifique pr√©-processamento.\")\n",
    "        return\n",
    "\n",
    "    features_val_train = df_val_train[feature_cols]\n",
    "    target_val_train = df_val_train[[target_col]]\n",
    "\n",
    "    scaler_features = MinMaxScaler()\n",
    "    scaler_target = MinMaxScaler()\n",
    "\n",
    "    scaled_features_val_train = scaler_features.fit_transform(features_val_train)\n",
    "    scaled_target_val_train = scaler_target.fit_transform(target_val_train)\n",
    "\n",
    "    num_features = scaled_features_val_train.shape[1]\n",
    "    print(f\"üìä N√∫mero de features: {num_features}\")\n",
    "\n",
    "    X_val_train_full, y_val_train_full = criar_janelas_multivariadas(\n",
    "        scaled_features_val_train,\n",
    "        scaled_target_val_train.flatten(),\n",
    "        janela\n",
    "    )\n",
    "\n",
    "    if X_val_train_full.size == 0 or y_val_train_full.size == 0:\n",
    "        print(f\"‚ùå N√£o foi poss√≠vel criar janelas para {ticker}, Janela {janela}.\")\n",
    "        return\n",
    "\n",
    "    print(\"üîç Iniciando busca de hiperpar√¢metros...\")\n",
    "    input_shape = (janela, num_features)\n",
    "    \n",
    "    temp_dir = tempfile.mkdtemp(prefix=f\"tuner_{ticker}_J{janela}_\")\n",
    "    print(f\"   üìÅ Diret√≥rio tempor√°rio criado: {temp_dir}\")\n",
    "    \n",
    "    try:\n",
    "        tuner = kt.RandomSearch(\n",
    "            lambda hp: build_model(hp, input_shape=input_shape),\n",
    "            objective='val_loss',\n",
    "            max_trials=max_trials_tuner,\n",
    "            executions_per_trial=1,\n",
    "            directory=temp_dir,\n",
    "            project_name='tuning',\n",
    "            overwrite=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao criar tuner: {e}\")\n",
    "        shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "        return\n",
    "\n",
    "    early_stopping_tuner = EarlyStopping(monitor='val_loss', patience=10, verbose=0, restore_best_weights=True)\n",
    "\n",
    "    split_index = int(len(X_val_train_full) * 0.8)\n",
    "    X_tuner_train, y_tuner_train = X_val_train_full[:split_index], y_val_train_full[:split_index]\n",
    "    X_tuner_val, y_tuner_val = X_val_train_full[split_index:], y_val_train_full[split_index:]\n",
    "\n",
    "    if len(X_tuner_val) == 0:\n",
    "        print(f\"‚ö†Ô∏è Sem dados de valida√ß√£o suficientes. Usando treino completo.\")\n",
    "        tuner.search(X_val_train_full, y_val_train_full, epochs=epochs_tuner, \n",
    "                    callbacks=[early_stopping_tuner], verbose=0)\n",
    "    else:\n",
    "        tuner.search(X_tuner_train, y_tuner_train, epochs=epochs_tuner,\n",
    "                    validation_data=(X_tuner_val, y_tuner_val),\n",
    "                    callbacks=[early_stopping_tuner], verbose=0)\n",
    "\n",
    "    try:\n",
    "        best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "        print(\"‚úì Melhores hiperpar√¢metros encontrados\")\n",
    "    except IndexError:\n",
    "        print(f\"‚ùå Keras Tuner n√£o encontrou hiperpar√¢metros v√°lidos.\")\n",
    "        shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "        return\n",
    "\n",
    "    print(f\"üìà TimeSeriesSplit CV ({n_splits_cv} folds)...\")\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits_cv)\n",
    "    cv_metrics = {'mae': [], 'mse': [], 'rmse': [], 'r2': []}\n",
    "    \n",
    "    for fold, (train_index, val_index) in enumerate(tscv.split(X_val_train_full), 1):\n",
    "        print(f\"   Fold {fold}/{n_splits_cv}...\", end=\" \")\n",
    "        X_train_fold, X_val_fold = X_val_train_full[train_index], X_val_train_full[val_index]\n",
    "        y_train_fold, y_val_fold = y_val_train_full[train_index], y_val_train_full[val_index]\n",
    "\n",
    "        if len(X_train_fold) == 0 or len(X_val_fold) == 0:\n",
    "            print(\"Pulando fold (sem dados)\")\n",
    "            continue\n",
    "\n",
    "        model_cv = tuner.hypermodel.build(best_hps)\n",
    "        early_stopping_cv = EarlyStopping(monitor='loss', patience=10, verbose=0)\n",
    "        model_cv.fit(X_train_fold, y_train_fold, epochs=epochs_final, batch_size=32,\n",
    "                    callbacks=[early_stopping_cv], verbose=0)\n",
    "\n",
    "        previsoes_val_fold_scaled = model_cv.predict(X_val_fold, verbose=0)\n",
    "        previsoes_val_fold = scaler_target.inverse_transform(previsoes_val_fold_scaled)\n",
    "        reais_val_fold = scaler_target.inverse_transform(y_val_fold.reshape(-1, 1))\n",
    "\n",
    "        mae_fold = mean_absolute_error(reais_val_fold, previsoes_val_fold)\n",
    "        mse_fold = mean_squared_error(reais_val_fold, previsoes_val_fold)\n",
    "        rmse_fold = np.sqrt(mse_fold)\n",
    "        \n",
    "        try:\n",
    "            r2_fold = r2_score(reais_val_fold, previsoes_val_fold)\n",
    "            r2_fold = r2_fold if np.isfinite(r2_fold) else -1.0\n",
    "        except ValueError:\n",
    "            r2_fold = -1.0\n",
    "\n",
    "        cv_metrics['mae'].append(mae_fold)\n",
    "        cv_metrics['mse'].append(mse_fold)\n",
    "        cv_metrics['rmse'].append(rmse_fold)\n",
    "        cv_metrics['r2'].append(r2_fold)\n",
    "        \n",
    "        print(f\"MAE: {mae_fold:.4f}, RMSE: {rmse_fold:.4f}, R¬≤: {r2_fold:.4f}\")\n",
    "\n",
    "    if cv_metrics['mae']:\n",
    "        avg_cv_mae = np.mean(cv_metrics['mae'])\n",
    "        avg_cv_mse = np.mean(cv_metrics['mse'])\n",
    "        avg_cv_rmse = np.mean(cv_metrics['rmse'])\n",
    "        avg_cv_r2 = np.mean(cv_metrics['r2'])\n",
    "        print(f\"\\n‚úì CV M√©dio: MAE={avg_cv_mae:.4f}, RMSE={avg_cv_rmse:.4f}, R¬≤={avg_cv_r2:.4f}\")\n",
    "    else:\n",
    "        avg_cv_mae, avg_cv_mse, avg_cv_rmse, avg_cv_r2 = np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "    print(\"\\nüéØ Treinando modelo final...\")\n",
    "    model_final = tuner.hypermodel.build(best_hps)\n",
    "    early_stopping_final = EarlyStopping(monitor='loss', patience=15, verbose=0, restore_best_weights=True)\n",
    "    history = model_final.fit(X_val_train_full, y_val_train_full, epochs=epochs_final, \n",
    "                              batch_size=32, callbacks=[early_stopping_final], verbose=0)\n",
    "\n",
    "    print(\"üß™ Avaliando no conjunto de teste (2023)...\")\n",
    "    \n",
    "    features_test_final = df_test_final[feature_cols]\n",
    "    target_test_final = df_test_final[[target_col]]\n",
    "\n",
    "    scaled_features_test_final = scaler_features.transform(features_test_final)\n",
    "    scaled_target_test_final = scaler_target.transform(target_test_final)\n",
    "\n",
    "    X_test_final, y_test_final = criar_janelas_multivariadas(\n",
    "        scaled_features_test_final,\n",
    "        scaled_target_test_final.flatten(),\n",
    "        janela\n",
    "    )\n",
    "\n",
    "    if X_test_final.size == 0 or y_test_final.size == 0:\n",
    "        print(f\"‚ùå N√£o foi poss√≠vel criar janelas de teste.\")\n",
    "        if not np.isnan(avg_cv_mae):\n",
    "            metrics_df = pd.DataFrame([{\n",
    "                'Ticker': ticker, 'Janela': janela, 'Num Features': num_features,\n",
    "                'CV Avg MAE': avg_cv_mae, 'CV Avg RMSE': avg_cv_rmse, 'CV Avg R2': avg_cv_r2,\n",
    "                'Teste MAE': np.nan, 'Teste RMSE': np.nan, 'Teste R2': np.nan\n",
    "            }])\n",
    "            metrics_df.to_csv(metrics_path, index=False)\n",
    "        shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "        return\n",
    "\n",
    "    previsoes_test_scaled = model_final.predict(X_test_final, verbose=0)\n",
    "    previsoes_test_final = scaler_target.inverse_transform(previsoes_test_scaled)\n",
    "    reais_test_final = scaler_target.inverse_transform(y_test_final.reshape(-1, 1))\n",
    "\n",
    "    mae_test = mean_absolute_error(reais_test_final, previsoes_test_final)\n",
    "    mse_test = mean_squared_error(reais_test_final, previsoes_test_final)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    r2_test = r2_score(reais_test_final, previsoes_test_final)\n",
    "    \n",
    "    print(f\"‚úì Teste: MAE={mae_test:.4f}, RMSE={rmse_test:.4f}, R¬≤={r2_test:.4f}\")\n",
    "\n",
    "    print(\"\\nüíæ Salvando resultados...\")\n",
    "    \n",
    "    metrics_df = pd.DataFrame([{\n",
    "        'Ticker': ticker, 'Janela': janela, 'Num Features': num_features,\n",
    "        'CV Avg MAE': avg_cv_mae, 'CV Avg RMSE': avg_cv_rmse, 'CV Avg R2': avg_cv_r2,\n",
    "        'Teste MAE': mae_test, 'Teste RMSE': rmse_test, 'Teste R2': r2_test\n",
    "    }])\n",
    "    metrics_df.to_csv(metrics_path, index=False)\n",
    "\n",
    "    hiperparametros_df = pd.DataFrame([best_hps.values])\n",
    "    hiperparametros_df.to_csv(hiperparametros_path, index=False)\n",
    "\n",
    "    datas_teste_final = df_test_final.index[janela:]\n",
    "    if len(datas_teste_final) == len(reais_test_final):\n",
    "        previsoes_df = pd.DataFrame({\n",
    "            'Data': datas_teste_final,\n",
    "            'Pre√ßo Real': reais_test_final.flatten(),\n",
    "            'Pre√ßo Previsto': previsoes_test_final.flatten()\n",
    "        })\n",
    "        previsoes_df.to_csv(previsoes_path, index=False)\n",
    "\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        plt.plot(previsoes_df['Data'], previsoes_df['Pre√ßo Real'], \n",
    "                label='Real (2023)', color='blue', linewidth=2)\n",
    "        plt.plot(previsoes_df['Data'], previsoes_df['Pre√ßo Previsto'], \n",
    "                label='Previsto (2023)', color='orange', linestyle='--', linewidth=2)\n",
    "        plt.title(f'{ticker} - Janela {janela} | Teste 2023\\nMAE: {mae_test:.4f} | R¬≤: {r2_test:.4f}', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Data', fontsize=12)\n",
    "        plt.ylabel('Pre√ßo (R$)', fontsize=12)\n",
    "        plt.legend(fontsize=11)\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(grafico_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "    print(f\"‚úÖ Experimento conclu√≠do: {ticker}, Janela {janela}\\n\")\n",
    "\n",
    "def rodar_experimentos_cv_multiplas_pastas():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" \"*20 + \"üöÄ EXPERIMENTOS LSTM - M√öLTIPLAS FONTES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for tipo_experimento, pasta_dados_tratados in pastas_dados.items():\n",
    "        print(f\"\\n{'#'*80}\")\n",
    "        print(f\"üìÇ PROCESSANDO EXPERIMENTO: {tipo_experimento.upper()}\")\n",
    "        print(f\"üìÅ Pasta: {pasta_dados_tratados}\")\n",
    "        print(f\"{'#'*80}\\n\")\n",
    "        \n",
    "        resultados_base_dir = os.path.join(base_path, f\"Resultados_{tipo_experimento.capitalize()}\")\n",
    "        \n",
    "        os.makedirs(resultados_base_dir, exist_ok=True)\n",
    "        for ticker in tickers:\n",
    "            ticker_dir = os.path.join(resultados_base_dir, ticker)\n",
    "            os.makedirs(ticker_dir, exist_ok=True)\n",
    "            os.makedirs(os.path.join(ticker_dir, \"Graficos\"), exist_ok=True)\n",
    "            os.makedirs(os.path.join(ticker_dir, \"Metricas\"), exist_ok=True)\n",
    "            os.makedirs(os.path.join(ticker_dir, \"Previsoes\"), exist_ok=True)\n",
    "            os.makedirs(os.path.join(ticker_dir, \"Hiperparametros\"), exist_ok=True)\n",
    "\n",
    "        print(f\"üìä Tickers: {len(tickers)}\")\n",
    "        print(f\"üî¢ Janelas: {janela_min} a {janela_max}\")\n",
    "        print(f\"üîÑ Total de experimentos: {len(tickers) * (janela_max - janela_min + 1)}\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "        for ticker in tickers:\n",
    "            df_ticker_full, feature_cols, target_col = carregar_dados_ticker(ticker, pasta_dados_tratados, tipo_experimento)\n",
    "\n",
    "            if df_ticker_full is None:\n",
    "                print(f\"‚ùå N√£o foi poss√≠vel carregar dados para {ticker}. Pulando...\")\n",
    "                continue\n",
    "\n",
    "            for janela in range(janela_min, janela_max + 1):\n",
    "                try:\n",
    "                    rodar_experimento_especifico(ticker, janela, df_ticker_full, feature_cols, target_col, resultados_base_dir)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå ERRO CR√çTICO em {ticker}, Janela {janela}: {e}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" \"*20 + \"‚úÖ TODOS OS EXPERIMENTOS CONCLU√çDOS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rodar_experimentos_cv_multiplas_pastas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
