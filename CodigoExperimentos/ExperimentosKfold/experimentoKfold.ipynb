{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 17s]\n",
      "val_loss: 0.00041789491660892963\n",
      "\n",
      "Best val_loss So Far: 0.00041789491660892963\n",
      "Total elapsed time: 00h 02m 15s\n",
      "\n",
      "Melhores Hiperparâmetros encontrados:\n",
      "{'num_lstm_layers': 1, 'units_lstm_0': 96, 'dropout_lstm_0': 0.2, 'num_dense_layers': 2, 'learning_rate': 0.001, 'units_lstm_1': 96, 'dropout_lstm_1': 0.1, 'units_lstm_2': 64, 'dropout_lstm_2': 0.1, 'units_dense_0': 32, 'dropout_dense_0': 0.2, 'units_dense_1': 48, 'dropout_dense_1': 0.2}\n",
      "\n",
      "Iniciando TimeSeriesSplit CV (5 folds) para avaliar os melhores HPs...\n",
      "  Fold 1/5...\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "    Fold 1 MAE: 2.6686, RMSE: 3.1220, R2: 0.5291\n",
      "  Fold 2/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leona\\anaconda3\\envs\\ambiente\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step\n",
      "    Fold 2 MAE: 1.2610, RMSE: 1.5364, R2: 0.9127\n",
      "  Fold 3/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leona\\anaconda3\\envs\\ambiente\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "    Fold 3 MAE: 0.8928, RMSE: 1.1722, R2: 0.8926\n",
      "  Fold 4/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leona\\anaconda3\\envs\\ambiente\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "    Fold 4 MAE: 0.9730, RMSE: 1.2098, R2: 0.8847\n",
      "  Fold 5/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leona\\anaconda3\\envs\\ambiente\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "    Fold 5 MAE: 1.4121, RMSE: 1.6572, R2: 0.8048\n",
      "\n",
      "Resultados Médios da Validação Cruzada (TimeSeriesSplit):\n",
      "  Avg MAE: 1.4415\n",
      "  Avg MSE: 3.5383\n",
      "  Avg RMSE: 1.7395\n",
      "  Avg R2: 0.8048\n",
      "\n",
      "Treinando modelo final com melhores HPs em todos os dados de 2020-2022...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leona\\anaconda3\\envs\\ambiente\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2519\n",
      "Epoch 2/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0339 \n",
      "Epoch 3/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0230 \n",
      "Epoch 4/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0157 \n",
      "Epoch 5/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 \n",
      "Epoch 6/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 \n",
      "Epoch 7/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 \n",
      "Epoch 8/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 \n",
      "Epoch 9/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 \n",
      "Epoch 10/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082\n",
      "Epoch 11/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - loss: 0.0071\n",
      "Epoch 12/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 13/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0064 \n",
      "Epoch 14/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0063 \n",
      "Epoch 15/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0063 \n",
      "Epoch 16/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 \n",
      "Epoch 17/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0056 \n",
      "Epoch 18/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 \n",
      "Epoch 19/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0047 \n",
      "Epoch 20/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 \n",
      "Epoch 21/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0044 \n",
      "Epoch 22/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0046 \n",
      "Epoch 23/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0048 \n",
      "Epoch 24/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050\n",
      "Epoch 25/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 \n",
      "Epoch 26/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0051 \n",
      "Epoch 27/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 \n",
      "Epoch 28/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 \n",
      "Epoch 29/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 \n",
      "Epoch 30/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 \n",
      "Epoch 31/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 \n",
      "Epoch 32/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 \n",
      "Epoch 33/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 \n",
      "Epoch 34/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 \n",
      "Epoch 35/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 \n",
      "Epoch 36/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 \n",
      "Epoch 37/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 \n",
      "Epoch 38/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 \n",
      "Epoch 39/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 \n",
      "Epoch 40/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033 \n",
      "Epoch 41/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 \n",
      "Epoch 42/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 \n",
      "Epoch 43/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0038 \n",
      "Epoch 44/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 \n",
      "Epoch 45/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0046 \n",
      "Epoch 46/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 \n",
      "Epoch 47/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 \n",
      "Epoch 48/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0032 \n",
      "Epoch 49/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0032 \n",
      "Epoch 50/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 \n",
      "Epoch 51/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0032\n",
      "Epoch 52/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 \n",
      "Epoch 53/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 \n",
      "Epoch 54/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 \n",
      "Epoch 55/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 \n",
      "Epoch 56/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033 \n",
      "Epoch 57/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033 \n",
      "Epoch 58/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0031 \n",
      "Epoch 59/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 \n",
      "Epoch 60/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 \n",
      "Epoch 61/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 \n",
      "Epoch 62/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 \n",
      "Epoch 63/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033 \n",
      "Epoch 64/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 \n",
      "Epoch 65/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 \n",
      "Epoch 66/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 \n",
      "Epoch 67/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0029 \n",
      "Epoch 68/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 \n",
      "Epoch 69/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 0.0033\n",
      "Epoch 70/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030\n",
      "Epoch 71/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 \n",
      "Epoch 72/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0025 \n",
      "Epoch 73/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031\n",
      "Epoch 74/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 \n",
      "Epoch 75/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0029 \n",
      "Epoch 76/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0026 \n",
      "Epoch 77/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.0029\n",
      "Epoch 78/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 \n",
      "Epoch 79/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 \n",
      "Epoch 80/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0024 \n",
      "Epoch 81/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0023 \n",
      "Epoch 82/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 \n",
      "Epoch 83/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0026 \n",
      "Epoch 84/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0024 \n",
      "Epoch 85/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0023\n",
      "Epoch 86/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0024\n",
      "Epoch 87/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0031 \n",
      "Epoch 88/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 \n",
      "Epoch 89/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0026 \n",
      "Epoch 90/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.0024\n",
      "Epoch 91/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0025 \n",
      "Epoch 92/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0024 \n",
      "Epoch 93/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 \n",
      "Epoch 94/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025\n",
      "Epoch 95/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 \n",
      "Epoch 96/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 0.0026\n",
      "Epoch 97/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 0.0026\n",
      "Epoch 98/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0025 \n",
      "Epoch 99/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0024 \n",
      "Epoch 100/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 0.0023\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "\n",
      "Avaliando modelo final no conjunto de teste (2023)...\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "Resultados da Avaliação Final (Teste 2023):\n",
      "  MAE Teste: 0.6714\n",
      "  MSE Teste: 0.7015\n",
      "  RMSE Teste: 0.8375\n",
      "  R² Teste: 0.9637\n",
      "\n",
      "Salvando resultados...\n",
      "Métricas salvas em resultados_lstm_cv/SUZB3.SA_Janela_2_metrics.csv\n",
      "Hiperparâmetros salvos em resultados_lstm_cv/SUZB3.SA_Janela_2_hiperparametros.csv\n",
      "Previsões do teste salvas em resultados_lstm_cv/SUZB3.SA_Janela_2_previsoes_teste_final.csv\n",
      "Gráfico do teste salvo em resultados_lstm_cv/SUZB3.SA_Janela_2_grafico_teste_final.png\n",
      "--- Experimento Concluído: SUZB3.SA, Janela 2 ---\n",
      "\n",
      "--- TODOS OS EXPERIMENTOS CONCLUÍDOS ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Adicionar TimeSeriesSplit e mean_absolute_error, etc. diretamente se necessário fora da função\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping # Importar EarlyStopping\n",
    "import yfinance as yf\n",
    "\n",
    "# Função carregar_dados_yahoo (sem alterações)\n",
    "def carregar_dados_yahoo(tickers, start_date_val, end_date_val, start_date_test, end_date_test, salvar_csv=False, pasta_csv=\"dados_acoes_csv\"):\n",
    "    # ... (código original sem alterações) ...\n",
    "    dados = {}\n",
    "    if salvar_csv:\n",
    "        os.makedirs(pasta_csv, exist_ok=True)\n",
    "    for ticker in tickers:\n",
    "        print(f\"Baixando dados para {ticker}...\")\n",
    "        # Baixar dados de validação (treino + validação interna do tuner/CV)\n",
    "        df_val_train = yf.download(ticker, start=start_date_val, end=end_date_val)\n",
    "        # Baixar dados de teste final (hold-out)\n",
    "        df_test_final = yf.download(ticker, start=start_date_test, end=end_date_test)\n",
    "\n",
    "        if df_val_train.empty or df_test_final.empty:\n",
    "            print(f\"Aviso: Nenhum dado encontrado para {ticker} (val ou test). Pulando ticker.\")\n",
    "            continue\n",
    "\n",
    "        # Usar apenas 'Close'\n",
    "        df_val_train = df_val_train[['Close']].rename(columns={'Close': 'Preço'})\n",
    "        df_test_final = df_test_final[['Close']].rename(columns={'Close': 'Preço'})\n",
    "\n",
    "        # ATENÇÃO: Armazenar separadamente para clareza na função de experimento\n",
    "        dados[ticker] = {'val_train': df_val_train, 'test_final': df_test_final}\n",
    "\n",
    "        if salvar_csv:\n",
    "            # Salvar concatenado se precisar do arquivo completo, ou salvar separado\n",
    "            caminho_csv_val = os.path.join(pasta_csv, f\"{ticker}_val_train_{start_date_val}_to_{end_date_val}.csv\")\n",
    "            caminho_csv_test = os.path.join(pasta_csv, f\"{ticker}_test_{start_date_test}_to_{end_date_test}.csv\")\n",
    "            df_val_train.to_csv(caminho_csv_val)\n",
    "            df_test_final.to_csv(caminho_csv_test)\n",
    "            print(f\"Dados de Val/Train de {ticker} salvos em {caminho_csv_val}.\")\n",
    "            print(f\"Dados de Teste Final de {ticker} salvos em {caminho_csv_test}.\")\n",
    "    return dados\n",
    "\n",
    "\n",
    "# Função criar_janelas (sem alterações)\n",
    "def criar_janelas(dados, janela):\n",
    "    # ... (código original sem alterações) ...\n",
    "    X, y = [], []\n",
    "    for i in range(len(dados) - janela):\n",
    "        X.append(dados[i:i + janela])\n",
    "        y.append(dados[i + janela])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Função build_model (sem alterações)\n",
    "def build_model(hp, input_shape):\n",
    "    # ... (código original sem alterações) ...\n",
    "    model = keras.Sequential()\n",
    "    # Adicionar camadas LSTM\n",
    "    for i in range(hp.Int('num_lstm_layers', 1, 3)): # Exemplo: 1 a 3 camadas\n",
    "        return_sequences = i < hp.Int('num_lstm_layers', 1, 3) - 1\n",
    "        model.add(layers.LSTM(\n",
    "            units=hp.Int(f'units_lstm_{i}', min_value=32, max_value=128, step=32), # Ajustar range se necessário\n",
    "            return_sequences=return_sequences,\n",
    "            input_shape=input_shape if i == 0 else None\n",
    "        ))\n",
    "        model.add(layers.Dropout(hp.Float(f'dropout_lstm_{i}', 0.1, 0.3, step=0.1))) # Dropout moderado\n",
    "\n",
    "    # Adicionar camadas Densas (opcional, mas comum antes da saída)\n",
    "    for i in range(hp.Int('num_dense_layers', 0, 2)): # Exemplo: 0 a 2 camadas\n",
    "         if hp.Int('num_dense_layers', 0, 2) > 0: # Só adiciona se num_dense_layers > 0\n",
    "            model.add(layers.Dense(\n",
    "                units=hp.Int(f'units_dense_{i}', min_value=16, max_value=64, step=16), # Menos unidades talvez\n",
    "                activation='relu'\n",
    "            ))\n",
    "            model.add(layers.Dropout(hp.Float(f'dropout_dense_{i}', 0.1, 0.3, step=0.1)))\n",
    "\n",
    "    # Camada de saída\n",
    "    model.add(layers.Dense(1)) # Saída única (preço)\n",
    "\n",
    "    # Compilação\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-3, 5e-4])), # Menos opções talvez\n",
    "        loss='mean_squared_error'\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Configurações (ajustar se necessário)\n",
    "tickers = [ \"BEEF3.SA\", \"PETR4.SA\", \"SOJA3.SA\", \"GGBR3.SA\", \"CSNA3.SA\", \"VALE3.SA\", \"JBSS3.SA\", \"BRFS3.SA\", \"SUZB3.SA\"]\n",
    "start_date_val = \"2020-01-01\"\n",
    "end_date_val = \"2022-12-31\" # Dados para treino e validação CV\n",
    "start_date_test = \"2023-01-01\"\n",
    "end_date_test = \"2023-12-31\" # Dados para teste final (hold-out)\n",
    "janela_min = 1 # Aumentar janela mínima\n",
    "janela_max = 2 # Aumentar janela máxima\n",
    "n_splits_cv = 5  # Número de folds para TimeSeriesSplit\n",
    "max_trials_tuner = 10 # Aumentar tentativas do tuner\n",
    "epochs_tuner = 50    # Epochs para busca do tuner\n",
    "epochs_final = 100   # Epochs para treino final (com early stopping)\n",
    "resultados_dir = \"resultados_lstm_cv\"\n",
    "os.makedirs(resultados_dir, exist_ok=True)\n",
    "\n",
    "# Carregar os dados (agora retorna um dicionário com 'val_train' e 'test_final')\n",
    "dados_por_ticker = carregar_dados_yahoo(tickers, start_date_val, end_date_val, start_date_test, end_date_test, salvar_csv=True, pasta_csv=\"dados_acoes_csv_cv\")\n",
    "\n",
    "# --- Função de Experimento Específico MODIFICADA ---\n",
    "def rodar_experimento_especifico(ticker, janela, dados_ticker):\n",
    "    print(f\"\\n--- Iniciando Experimento: {ticker}, Janela {janela} ---\")\n",
    "\n",
    "    # Definir nomes de arquivos\n",
    "    base_filename = f\"{resultados_dir}/{ticker}_Janela_{janela}\"\n",
    "    metrics_path = f\"{base_filename}_metrics.csv\"\n",
    "    hiperparametros_path = f\"{base_filename}_hiperparametros.csv\"\n",
    "    grafico_path = f\"{base_filename}_grafico_teste_final.png\"\n",
    "    previsoes_path = f\"{base_filename}_previsoes_teste_final.csv\"\n",
    "\n",
    "    if os.path.exists(metrics_path):\n",
    "        print(f\"Resultados já existem para {ticker}, Janela {janela}. Pulando...\")\n",
    "        return\n",
    "\n",
    "    # 1. Preparar Dados de Treino/Validação (2020-2022)\n",
    "    df_val_train = dados_ticker['val_train'].copy()\n",
    "    if df_val_train.isnull().any().any():\n",
    "        print(f\"Aviso: Dados nulos encontrados em df_val_train para {ticker}. Preenchendo com ffill/bfill.\")\n",
    "        df_val_train.fillna(method='ffill', inplace=True)\n",
    "        df_val_train.fillna(method='bfill', inplace=True) # Para garantir preenchimento no início\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    dados_val_train_scaled = scaler.fit_transform(df_val_train)\n",
    "    X_val_train_full, y_val_train_full = criar_janelas(dados_val_train_scaled, janela)\n",
    "\n",
    "    if len(X_val_train_full) < n_splits_cv:\n",
    "         print(f\"Aviso: Não há dados suficientes ({len(X_val_train_full)} amostras) para {n_splits_cv} splits em {ticker}, Janela {janela}. Pulando.\")\n",
    "         return\n",
    "\n",
    "    # 2. Otimização de Hiperparâmetros (Keras Tuner)\n",
    "    print(\"Iniciando busca de hiperparâmetros...\")\n",
    "    tuner = kt.RandomSearch(\n",
    "        lambda hp: build_model(hp, input_shape=(janela, 1)),\n",
    "        objective='val_loss',\n",
    "        max_trials=max_trials_tuner,\n",
    "        executions_per_trial=1, # Rodar cada trial uma vez\n",
    "        directory='keras_tuner_cv',\n",
    "        project_name=f'LSTM_{ticker}_Janela_{janela}',\n",
    "        overwrite=True\n",
    "    )\n",
    "\n",
    "    # Usar EarlyStopping dentro do tuner search para eficiência\n",
    "    early_stopping_tuner = EarlyStopping(monitor='val_loss', patience=10, verbose=0, restore_best_weights=True)\n",
    "\n",
    "    # Dividir os dados de treino/validação (2020-2022) para o tuner\n",
    "    # Usaremos uma divisão simples aqui, mas garantindo a ordem temporal\n",
    "    split_index = int(len(X_val_train_full) * 0.8) # Ex: 80% treino, 20% validação para o tuner\n",
    "    X_tuner_train, y_tuner_train = X_val_train_full[:split_index], y_val_train_full[:split_index]\n",
    "    X_tuner_val, y_tuner_val = X_val_train_full[split_index:], y_val_train_full[split_index:]\n",
    "\n",
    "    if len(X_tuner_val) == 0:\n",
    "        print(f\"Aviso: Não há dados de validação suficientes para o tuner em {ticker}, Janela {janela} após split. Usando treino completo para busca (menos ideal).\")\n",
    "        tuner.search(X_val_train_full, y_val_train_full, epochs=epochs_tuner,\n",
    "                     callbacks=[early_stopping_tuner], verbose=1)\n",
    "    else:\n",
    "        tuner.search(X_tuner_train, y_tuner_train, epochs=epochs_tuner,\n",
    "                     validation_data=(X_tuner_val, y_tuner_val),\n",
    "                     callbacks=[early_stopping_tuner], verbose=1)\n",
    "\n",
    "    best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "    print(\"\\nMelhores Hiperparâmetros encontrados:\")\n",
    "    print(best_hps.values)\n",
    "\n",
    "    # 3. Avaliação Cruzada dos Melhores Hiperparâmetros (TimeSeriesSplit no período 2020-2022)\n",
    "    print(f\"\\nIniciando TimeSeriesSplit CV ({n_splits_cv} folds) para avaliar os melhores HPs...\")\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits_cv)\n",
    "    cv_metrics = {'mae': [], 'mse': [], 'rmse': [], 'r2': []}\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, val_index in tscv.split(X_val_train_full):\n",
    "        fold += 1\n",
    "        print(f\"  Fold {fold}/{n_splits_cv}...\")\n",
    "        X_train_fold, X_val_fold = X_val_train_full[train_index], X_val_train_full[val_index]\n",
    "        y_train_fold, y_val_fold = y_val_train_full[train_index], y_val_train_full[val_index]\n",
    "\n",
    "        # Construir e treinar modelo com os melhores HPs neste fold\n",
    "        model_cv = tuner.hypermodel.build(best_hps)\n",
    "        # Early stopping também no treino do fold CV\n",
    "        early_stopping_cv = EarlyStopping(monitor='loss', patience=10, verbose=0) # Monitorar treino loss aqui\n",
    "        model_cv.fit(X_train_fold, y_train_fold, epochs=epochs_final, # Usar epochs_final aqui tbm\n",
    "                     batch_size=32, # Definir batch size\n",
    "                     callbacks=[early_stopping_cv],\n",
    "                     verbose=0) # Menos verbose dentro do CV\n",
    "\n",
    "        # Avaliar no conjunto de validação do fold\n",
    "        previsoes_val_fold_scaled = model_cv.predict(X_val_fold)\n",
    "        previsoes_val_fold = scaler.inverse_transform(previsoes_val_fold_scaled)\n",
    "        reais_val_fold = scaler.inverse_transform(y_val_fold.reshape(-1, 1))\n",
    "\n",
    "        # Calcular métricas do fold\n",
    "        cv_metrics['mae'].append(mean_absolute_error(reais_val_fold, previsoes_val_fold))\n",
    "        cv_metrics['mse'].append(mean_squared_error(reais_val_fold, previsoes_val_fold))\n",
    "        cv_metrics['rmse'].append(np.sqrt(cv_metrics['mse'][-1]))\n",
    "        cv_metrics['r2'].append(r2_score(reais_val_fold, previsoes_val_fold))\n",
    "        print(f\"    Fold {fold} MAE: {cv_metrics['mae'][-1]:.4f}, RMSE: {cv_metrics['rmse'][-1]:.4f}, R2: {cv_metrics['r2'][-1]:.4f}\")\n",
    "\n",
    "\n",
    "    # Calcular métricas médias da validação cruzada\n",
    "    avg_cv_mae = np.mean(cv_metrics['mae'])\n",
    "    avg_cv_mse = np.mean(cv_metrics['mse'])\n",
    "    avg_cv_rmse = np.mean(cv_metrics['rmse'])\n",
    "    avg_cv_r2 = np.mean(cv_metrics['r2'])\n",
    "    print(\"\\nResultados Médios da Validação Cruzada (TimeSeriesSplit):\")\n",
    "    print(f\"  Avg MAE: {avg_cv_mae:.4f}\")\n",
    "    print(f\"  Avg MSE: {avg_cv_mse:.4f}\")\n",
    "    print(f\"  Avg RMSE: {avg_cv_rmse:.4f}\")\n",
    "    print(f\"  Avg R2: {avg_cv_r2:.4f}\")\n",
    "\n",
    "    # 4. Treinamento Final (com melhores HPs, usando TODOS os dados de 2020-2022)\n",
    "    print(\"\\nTreinando modelo final com melhores HPs em todos os dados de 2020-2022...\")\n",
    "    model_final = tuner.hypermodel.build(best_hps)\n",
    "    early_stopping_final = EarlyStopping(monitor='loss', patience=15, verbose=1, restore_best_weights=True) # Monitorar loss, patience maior\n",
    "    model_final.fit(X_val_train_full, y_val_train_full, epochs=epochs_final,\n",
    "                    batch_size=32, # Usar batch size\n",
    "                    callbacks=[early_stopping_final],\n",
    "                    verbose=1)\n",
    "\n",
    "    # 5. Avaliação Final no Conjunto de Teste (2023 - Hold-Out)\n",
    "    print(\"\\nAvaliando modelo final no conjunto de teste (2023)...\")\n",
    "    df_test_final = dados_ticker['test_final'].copy()\n",
    "    if df_test_final.isnull().any().any():\n",
    "        print(f\"Aviso: Dados nulos encontrados em df_test_final para {ticker}. Preenchendo com ffill/bfill.\")\n",
    "        df_test_final.fillna(method='ffill', inplace=True)\n",
    "        df_test_final.fillna(method='bfill', inplace=True)\n",
    "\n",
    "    # Precisamos escalar os dados de teste USANDO O MESMO SCALER ajustado nos dados de treino\n",
    "    dados_test_scaled = scaler.transform(df_test_final)\n",
    "    X_test_final, y_test_final = criar_janelas(dados_test_scaled, janela)\n",
    "\n",
    "    if len(X_test_final) == 0:\n",
    "        print(f\"Erro: Não foi possível criar janelas para o conjunto de teste final de {ticker}, Janela {janela}. Verifique as datas e o tamanho da janela.\")\n",
    "        return\n",
    "\n",
    "    previsoes_test_scaled = model_final.predict(X_test_final)\n",
    "    previsoes_test_final = scaler.inverse_transform(previsoes_test_scaled)\n",
    "    reais_test_final = scaler.inverse_transform(y_test_final.reshape(-1, 1))\n",
    "\n",
    "    # Calcular métricas do teste final\n",
    "    mae_test = mean_absolute_error(reais_test_final, previsoes_test_final)\n",
    "    mse_test = mean_squared_error(reais_test_final, previsoes_test_final)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    r2_test = r2_score(reais_test_final, previsoes_test_final)\n",
    "    print(\"\\nResultados da Avaliação Final (Teste 2023):\")\n",
    "    print(f\"  MAE Teste: {mae_test:.4f}\")\n",
    "    print(f\"  MSE Teste: {mse_test:.4f}\")\n",
    "    print(f\"  RMSE Teste: {rmse_test:.4f}\")\n",
    "    print(f\"  R² Teste: {r2_test:.4f}\")\n",
    "\n",
    "    # 6. Salvar Resultados\n",
    "    print(\"\\nSalvando resultados...\")\n",
    "    # Salvar métricas (CV e Teste)\n",
    "    metrics_df = pd.DataFrame([{\n",
    "        'Ticker': ticker,\n",
    "        'Janela': janela,\n",
    "        'CV Avg MAE': avg_cv_mae,\n",
    "        'CV Avg MSE': avg_cv_mse,\n",
    "        'CV Avg RMSE': avg_cv_rmse,\n",
    "        'CV Avg R2': avg_cv_r2,\n",
    "        'Teste MAE': mae_test,\n",
    "        'Teste MSE': mse_test,\n",
    "        'Teste RMSE': rmse_test,\n",
    "        'Teste R2': r2_test\n",
    "    }])\n",
    "    metrics_df.to_csv(metrics_path, index=False)\n",
    "    print(f\"Métricas salvas em {metrics_path}\")\n",
    "\n",
    "    # Salvar hiperparâmetros\n",
    "    hiperparametros_df = pd.DataFrame([best_hps.values])\n",
    "    hiperparametros_df.to_csv(hiperparametros_path, index=False)\n",
    "    print(f\"Hiperparâmetros salvos em {hiperparametros_path}\")\n",
    "\n",
    "    # Salvar previsões do teste final\n",
    "    # Ajustar as datas para corresponder às previsões (começam 'janela' dias depois do início do teste)\n",
    "    datas_teste_final = df_test_final.index[janela:]\n",
    "    # Verificar se o número de datas corresponde ao número de previsões\n",
    "    if len(datas_teste_final) == len(reais_test_final):\n",
    "        previsoes_df = pd.DataFrame({\n",
    "            'Data': datas_teste_final,\n",
    "            'Preço Real': reais_test_final.flatten(),\n",
    "            'Preço Previsto': previsoes_test_final.flatten()\n",
    "        })\n",
    "        previsoes_df.to_csv(previsoes_path, index=False)\n",
    "        print(f\"Previsões do teste salvas em {previsoes_path}\")\n",
    "\n",
    "        # Gerar gráfico de preços reais vs previstos (Teste Final)\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        plt.plot(previsoes_df['Data'], previsoes_df['Preço Real'], label='Real (Teste 2023)', color='blue', linewidth=1.5)\n",
    "        plt.plot(previsoes_df['Data'], previsoes_df['Preço Previsto'], label='Previsto (Teste 2023)', color='orange', linestyle='--', linewidth=1.5)\n",
    "        plt.title(f'Preços Reais vs Previstos (Teste Final) - {ticker} (Janela {janela})')\n",
    "        plt.xlabel('Data')\n",
    "        plt.ylabel('Preço')\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.4)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(grafico_path)\n",
    "        print(f\"Gráfico do teste salvo em {grafico_path}\")\n",
    "        # plt.show() # Descomentar se quiser exibir interativamente\n",
    "        plt.close() # Fechar a figura para liberar memória\n",
    "    else:\n",
    "        print(f\"Erro: Discrepância entre número de datas ({len(datas_teste_final)}) e previsões ({len(reais_test_final)}) para {ticker}, Janela {janela}. Gráfico/Previsões não salvos.\")\n",
    "\n",
    "    print(f\"--- Experimento Concluído: {ticker}, Janela {janela} ---\")\n",
    "\n",
    "\n",
    "# --- Loop Principal de Experimentos MODIFICADO ---\n",
    "def rodar_experimentos_cv():\n",
    "    for ticker in tickers:\n",
    "        if ticker not in dados_por_ticker:\n",
    "             print(f\"Dados para {ticker} não foram carregados. Pulando ticker.\")\n",
    "             continue\n",
    "        dados_ticker = dados_por_ticker[ticker]\n",
    "        for janela in range(janela_min, janela_max + 1): # Usar range correto\n",
    "            try:\n",
    "                # Passar os dados específicos do ticker para a função\n",
    "                rodar_experimento_especifico(ticker, janela, dados_ticker)\n",
    "            except Exception as e:\n",
    "                print(f\"Erro CRÍTICO ao rodar experimento {ticker}, Janela {janela}: {e}\")\n",
    "                # Considerar logar o traceback completo para depuração\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "\n",
    "# Rodar os experimentos com a nova estrutura\n",
    "rodar_experimentos_cv()\n",
    "\n",
    "print(\"\\n--- TODOS OS EXPERIMENTOS CONCLUÍDOS ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ambiente",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
